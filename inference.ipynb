{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import GPTConfig, GPT, ParallelGPT, LinearGPT, ConvGPT\n",
    "from train import TrainConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/stoi.json', 'r') as f1, open('data/itos.json', 'r') as f2:\n",
    "    stoi = json.loads(f1.read())\n",
    "    itos = json.loads(f2.read())\n",
    "\n",
    "encode_fn = lambda s: [stoi[ch] for ch in s]\n",
    "decode_fn = lambda tokens: ''.join(itos[str(t)] for t in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Oh God, '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06M\n",
      "Oh God, and the more of the people,\n",
      "That he shall stand men to my heart sleep,\n",
      "And the trouble have some to the world:\n",
      "And then the father of the complaiment\n",
      "And the foresh the seate of the world's son,\n",
      "And therefore the world to the sea of the king.\n",
      "\n",
      "KING RICHARD III:\n",
      "So long as it the people is dead.\n",
      "\n",
      "DUKE OF YORK:\n",
      "And then we shall be the sea to my life.\n",
      "\n",
      "DUKE OF YORK:\n",
      "\n",
      "NORD WARD:\n",
      "I do beseech you, sir, and the word is my soul.\n",
      "\n",
      "KING EDWARD IV:\n",
      "Then the king of the common of the field.\n",
      "\n",
      "KING HENRY VI\n"
     ]
    }
   ],
   "source": [
    "model = GPT(GPTConfig())\n",
    "ckpt = torch.load('out/gpt/gpt.pt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'])\n",
    "model = model.to('cpu')\n",
    "tokens = torch.tensor([encode_fn(text)], device='cpu')\n",
    "op = model.generate(tokens,500, temperature=0.2)\n",
    "print(decode_fn(op.cpu().numpy().tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06M\n",
      "Oh God, I do not speak you shall not be so be not be not be make to be not be some to the king, and my lord.\n",
      "\n",
      "Shepherd of your honour of York.\n",
      "\n",
      "Clown the counting of the king of you to heav,--\n",
      "\n",
      "SLA:\n",
      "If you that I say the sentlemn'd the press of the very of York\n",
      "With of the such of the world of out of you have me speak of the save it be report of you must not my lords of the report is not say,\n",
      "And I'love you are not be reven of the possake the prise of a villainter of YORK:\n",
      "His shall not say, and the com\n"
     ]
    }
   ],
   "source": [
    "model = ParallelGPT(GPTConfig(model_type='pgpt'))\n",
    "ckpt = torch.load('out/pgpt/pgpt.pt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'])\n",
    "model = model.to('cpu')\n",
    "tokens = torch.tensor([encode_fn(text)], device='cpu')\n",
    "op = model.generate(tokens,500, temperature=0.2, drop_one=True)\n",
    "print(decode_fn(op.cpu().numpy().tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06M\n",
      "Oh God, to the would be the world of the duke,\n",
      "And the father that the truth the store of the world\n",
      "And the seek of the bear of the sea,\n",
      "And the sea the sun the straight of the state,\n",
      "And say the strange of the foul of the world,\n",
      "And the presence of the stating of the seases,\n",
      "And where the streegs of the senses of the rest,\n",
      "And the beauthth of the rest of the sentends\n",
      "To be the season to the stail of the world\n",
      "That the senators of the strew of the seath of the seat,\n",
      "And the senat the singeneral that whi\n"
     ]
    }
   ],
   "source": [
    "model = ConvGPT(GPTConfig(model_type='cgpt'))\n",
    "ckpt = torch.load('out/cgpt/cgpt.pt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'])\n",
    "model = model.to('cpu')\n",
    "tokens = torch.tensor([encode_fn(text)], device='cpu')\n",
    "op = model.generate(tokens,500, temperature=0.2)\n",
    "print(decode_fn(op.cpu().numpy().tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 0.06M\n",
      "Oh God, the shall be strengter of the seater\n",
      "With the word of the counsel of the companion.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Why, the counter that hath he was a soldied to his face,\n",
      "And the man of the word of the prince of the country,\n",
      "And with the stand the thereof the common of his blood.\n",
      "\n",
      "KING RICHARD III:\n",
      "And the stand that I will be see the souls.\n",
      "\n",
      "KING RICHARD II:\n",
      "What say the was should be the country'd the more of the worship.\n",
      "\n",
      "KING RICHARD II:\n",
      "The sent the world of the court of the prove the\n",
      "Which was with many th\n"
     ]
    }
   ],
   "source": [
    "model = LinearGPT(GPTConfig(model_type='lgpt'))\n",
    "ckpt = torch.load('out/lgpt/lgpt.pt', map_location='cpu')\n",
    "model.load_state_dict(ckpt['model'])\n",
    "model = model.to('cpu')\n",
    "tokens = torch.tensor([encode_fn(text)], device='cpu')\n",
    "op = model.generate(tokens,500, temperature=0.2)\n",
    "print(decode_fn(op.cpu().numpy().tolist()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
